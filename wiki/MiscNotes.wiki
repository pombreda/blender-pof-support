#summary Miscellaneous thoughts and notes for future reference.
#labels Phase-QA,Featured

==Mass and moment of inertia==
Can we use Blender's weight painting and [http://en.wikipedia.org/wiki/Spieker_center Spieker Center] calculation to calculate the mass, center of mass, and inertia tensor of a full-triangulated mesh?

==Version 0.1 and speed==
For the very first test releases, program speed is less important than release speed.  However, a few re-writes for optimization should be made shortly after the first fully-functional releases:
 * Membership testing with sets and dictionaries is much faster, O(1), than searching sequences, O(n). When testing "a in b", b should be a set or dictionary instead of a list or tuple.
 * String concatenation is best done with ''.join(seq) which is an O(n) process. In contrast, using the '+' or '+=' operators can result in an O(n**2) process because new strings may be built for each intermediate step. The CPython 2.4 interpreter mitigates this issue somewhat; however, ''.join(seq) remains the best practice.
 * In functions, local variables are accessed more quickly than global variables, builtins, and attribute lookups. So, it is sometimes worth localizing variable access in inner-loops. For example, the code for random.shuffle() localizes access with the line, random=self.random. That saves the shuffling loop from having to repeatedly lookup self.random. Outside of loops, the gain is minimal and rarely worth it.

Eventually (for v. 1.0 or v. 2.0) a rewrite of the volition module in C or C++ would be nice.  I'd rather not have to use an external module, but if performance does become an issue before a rewrite to C, we might have to use NumPy.

~~In the mean time, the exporter will be built from the beginning to be multi-threaded, getting the number of threads from Blender.~~

===Multiprocessing===
Can we use multiprocessing to speed up BSP tree compilation?
{{{
import multiprocessing
...
result_queue = multiprocessing.Queue()
compiled_models = [MultiCompile(result_queue, m) for m in meshes]
jobs = [multiprocessing.Process(model) for model in compiled_models]
for job in jobs: job.start()
for job in jobs: job.join()
results = [result_queue.get() for model in compiled_models]
}}}

==PINF data==
The exporter will provide a field for custom PINF data (e.g. for a copyright statement).  After the custom PINF data, the exporter will write the following null-terminated strings:
{{{
"Exported from Blender {}, using exporter version {}, with volition package version {}".format(blender_version, exporter_version, volition_version)
"Max BSP depth was {}. Most polys in a single node was {}".format(max_bsp_depth, most_polys)
"Total compile time was {}ms, tree generation time was {}ms".format(pof_time, bsp_time)
}}}
Timing information will be calculated using a series of calls to `time.time()` and getting the time difference.

==More Blender stuff==
~~At first, the import/export scripts will have a layout based off of the .obj import/export scripts.  Eventually, though, we may want to build a dialog box with:~~
{{{
    def invoke(self, context, event):
        wm = context.window_manager
        return wm.invoke_props_dialog(self)
}}}
~~and a few buttons (`layout.operator()`)to additional operators defined in the module to display data contained in the VP/POF file before any geometry is imported.~~

~~operator import pof (in import menu) creates a dialog and draws properties from other operators
operator load file contains properties filepath and filetype* - if pof, creates a pof handler and import pof draws do import; if vp, pof handler draws load pof from vp
operator load pof from vp contains an enum of all pof files in vp - creates pof handler and import pof draws do import
operator import textures contains a filepath and attempts to pack textures specified in the txtr chunk
operator do import contains all the properties for the actual import~~

~~*not drawn, but used in if/else statements for drawing other properties~~